from google import genai
from google.genai import types
import os
import json
from database import get_db_con

class GeminiOrchestrator:
    def __init__(self, api_key: str):
        """
        Initialize Gemini Orchestrator with real API key using new google-genai SDK.
        No mock fallbacks - this is production code.
        """
        if not api_key or len(api_key) < 30:
            raise ValueError(f"Invalid Gemini API key provided (length: {len(api_key) if api_key else 0})")
        
        self.api_key = api_key
        
        # Configure and initialize Gemini client with new SDK
        try:
            self.client = genai.Client(api_key=self.api_key)
            self.model_name = 'gemini-2.5-flash'  # Using available model
            print(f"âœ… Gemini AI initialized successfully with model: {self.model_name}")
        except Exception as e:
            raise RuntimeError(f"Failed to initialize Gemini client: {e}")

    def generate_remediation(self, findings: list) -> dict:
        """
        Mock: Returns a structured fix.
        """
        return {
            "description": "Mocked AI Remediation",
            "code_suggestion": "# Fixed code would follow...",
            "severity": "Medium"
        }

    def analyze_snippet(self, code: str, findings: list) -> dict:
        """
        Mock: Generates a fix for a specific code snippet.
        """
        return {
            "vulnerability": "Simulated Vulnerability",
            "explanation": "This is a simulated AI analysis response.",
            "fixed_code": "# Secure implementation\ndef secure_func():\n    pass",
            "severity": "Medium"
        }

    def generate_audit_report_text(self, context: str) -> str:
        """
        Mock: Generates a compliance report based on input context.
        Simulates "Thinking Mode" processing.
        """
        # Simple string matching to make the mock feel "Real" based on data passed
        has_critical_threats = "'severity': 'CRITICAL'" in context or "CRITICAL" in context
        has_risky_vendors = "risk_score" in context and ("100" in context or "95" in context)
        
        report = """
# SOC 2 TYPE II EVIDENCE REPORT
**Generated By**: Vajra AI Auditor (Gemini 3 Pro Exp)
**Date**: 2024-12-26
**Thinking Mode**: ENABLED (Analysis Depth: High)

## 1. Executive Summary
The organization's security posture is currently evaluated as **"""
        
        if has_critical_threats or has_risky_vendors:
             report += "AT RISK**.\nAutomated analysis has detected critical anomalies that require immediate remediation to satisfy Trust Services Criteria."
        else:
             report += "RESILIENT**.\nControls are operating effectively with no significant deviations detected."

        report += """

## 2. Control CC7.1: System Monitoring
**Criterion**: Entities must monitor limits and detect anomalies.
**Evidence Analysis**:
"""
        if has_critical_threats:
            report += "- ðŸ”´ **NON-COMPLIANT**: Critical severity threats detected in event stream. Immediate incident response logs required."
        else:
            report += "- ðŸŸ¢ **COMPLIANT**: No critical severity anomalies detected in the live threat stream. Continuous monitoring is active."

        report += """

## 3. Control CC8.1: Vulnerability Management
**Criterion**: Vulnerabilities are scanned and remediated.
**Evidence Analysis**:
- ðŸŸ¢ **COMPLIANT**: Recent scans (Trivy, Semgrep) indicate zero critical vulnerabilities in the codebase.
- **Trend**: consistent clean scans over the last 72 hours.

## 4. Control CC9.2: Vendor Risk Management
**Criterion**: Risks from third parties are assessed and managed.
**Evidence Analysis**:
"""
        if has_risky_vendors:
             report += "- âš ï¸ **OBSERVATION**: High-risk vendors detected in the supply chain (e.g., Legacy CRM, Stripe). Enhanced due diligence is recommended."
        else:
             report += "- ðŸŸ¢ **COMPLIANT**: All onboarded vendors fall within acceptable risk appetites."

        report += """

## 5. Auditor Opinion
**Determination**: """
        
        if has_critical_threats:
             report += "**QUALIFIED OPINION** (Exceptions Noted).\nThe presence of critical threats without documented resolution prevents an Unqualified opinion."
        else:
             report += "**UNQUALIFIED OPINION** (Clean).\nSystem controls appear effective and compliant with SOC 2 standards."

        return report

    def generate_gap_analysis(self, profile: dict, context: dict) -> dict:
        """
        Virtual CISO: Analyzes company profile and security logs to generate a roadmap.
        """
        # 1. Construct the Prompt
        # In a real scenario, this would go to Gemini.
        # For the hackathon/demo, we simulate the *response* of that prompt based on inputs.
        
        industry = profile.get("industry", "Unknown")
        region = profile.get("region", "Unknown")
        
        completed_actions = []
        if context.get("last_scan"): completed_actions.append("Code Vulnerability Scanning")
        if context.get("vendor_verification"): completed_actions.append("Vendor Identity Integrity")
        if context.get("ddos_protection"): completed_actions.append("Real-time Traffic Monitoring")
        
        # 2. Simulated AI Logic (The "Virtual CISO")
        gaps = []
        narrative = ""
        score = 65 # Base Score
        
        if "health" in industry.lower():
            narrative = f"As a {industry} provider in {region}, patient data privacy is your #1 risk. You are doing well with {', '.join(completed_actions) if completed_actions else 'basic security'}, but you are missing critical HIPAA safeguards."
            gaps.append({"regulation": "HIPAA", "gap": "Patient Data Encryption", "impact": "High", "fix_action": "Enable DB Encryption"})
            score = 70
        elif "fin" in industry.lower():
            narrative = f"For the {industry} sector, financial integrity is paramount. While you have {', '.join(completed_actions)}, PCI-DSS requires stricter network segmentation which is currently not detected."
            gaps.append({"regulation": "PCI-DSS", "gap": "Cardholder Data Isolation", "impact": "Critical", "fix_action": "Segment Network (VLAN)"})
            score = 60
        else:
             narrative = f"Operating in {region} requires strict data controls. Your current posture covers {', '.join(completed_actions)}, but you are exposed to general data breach liability."
             gaps.append({"regulation": "General Security", "gap": "MFA for Admin Access", "impact": "High", "fix_action": "Enforce MFA Policy"})

        if region.lower() in ["eu", "europe"]:
             gaps.append({"regulation": "GDPR", "gap": "Cookie Consent Log", "impact": "Medium", "fix_action": "Deploy Consent Banner"})
        
        return {
            "status": "Analysis Complete",
            "health_score": score,
            "narrative": narrative,
            "gaps": gaps
        }

        return {
            "status": "Analysis Complete",
            "health_score": score,
            "narrative": narrative,
            "gaps": gaps
        }

    def generate_phishing_email(self, industry: str, difficulty: str) -> dict:
        """
        AI Phish-Tank: Generates targeted phishing content.
        """
        # Mocking Gemini's creativity
        subject = "Urgent: Invoice Overdue"
        body = "Please review the attached invoice immediately."
        sender = "billing@internal-finance-dept.com"
        
        if "fin" in industry.lower():
            subject = "SWIFT Transfer Confirmation Pending"
            body = "A pending wire transfer of $45,000 requires your CEO approval. Login to the portal to authorize."
            sender = "swift-secure@citibank-support.com"
        elif "health" in industry.lower():
            subject = "HIPAA Compliance Audit - Action Required"
            body = "Your recent patient access logs show an anomaly. Please verify your credentials to avoid penalties."
            sender = "audit@hhs-gov-portal.com"
            
        return {
            "created_at": "Today",
            "sender": sender,
            "subject": subject,
            "body_preview": body,
            "difficulty": difficulty
        }

    def generate_security_moment(self, trigger: str, employee_id: str) -> dict:
        """
        Employee Coach: "Security Moment" interactive coaching.
        """
        if trigger == "suspect_link":
            return {
                "coach_name": "VAJRA Coach",
                "message": "Whoops! You clicked a simulated phishing link. Don't worry, you aren't in trouble.",
                "tip": "Always check the sender's domain. 'hhs-gov-portal.com' is not a real government site.",
                "rule": "The One Rule: If it asks for a login, check the URL twice."
            }
            
        return {"message": "Stay safe!"}

        return {"message": "Stay safe!"}

    def get_micro_learning_content(self, employee_name: str, risk_type: str) -> str:
        """
        Generates a 30-second 'Security Moment' for the employee.
        """
        # Mocking the AI response for the demo to ensure stability and speed
        
        if "Dark Web" in risk_type or "Leak" in risk_type:
             return f"""
             **Security Moment for {employee_name}**
             âš ï¸ **Risk Detected**: Your email was found in a recent public data breach. This is not your fault, but it is our problem to fix.
             ðŸ›¡ï¸ **Action**: Please change your VAJRA Dashboard password immediately.
             ðŸ’¡ **Pro-Tip**: Use a unique password manager so one leak doesn't compromise all your accounts.
             """
        
        return f"""
        **Security Moment for {employee_name}**
        âš ï¸ **Alert**: {risk_type} detected.
        ðŸ›¡ï¸ **Action**: Review your recent activity logs.
        ðŸ’¡ **Pro-Tip**: Enable 2FA on all sensitive accounts.
        """

        return f"""
        **Security Moment for {employee_name}**
        âš ï¸ **Alert**: {risk_type} detected.
        ðŸ›¡ï¸ **Action**: Review your recent activity logs.
        ðŸ’¡ **Pro-Tip**: Enable 2FA on all sensitive accounts.
        """

    def analyze_urgency(self, text: str, vendor: str) -> dict:
        """
        AI Context Filter: Determines if urgency is legitimate or scam.
        """
        # Mocking sophisticated context understanding
        text_lower = text.lower()
        is_scam = False
        confidence = 0.0
        reason = "Normal business communication."

        # Scam Patterns
        if "final notice" in text_lower or "immediate disconnection" in text_lower:
            # Context Check: Utilities often send these, but unknown vendors shouldn't
            if "cloud" in vendor.lower() or "service" in vendor.lower():
                 is_scam = True
                 confidence = 0.85
                 reason = "High-pressure tactics are untypical for Enterprise B2B SaaS."
            else:
                 # Likely utility bill
                 is_scam = False
                 confidence = 0.4
                 reason = "Urgency matches typical utility disconnection notice."
        
        if "change" in text_lower and "bank" in text_lower:
             is_scam = True
             confidence = 0.99
             reason = "CRITICAL: Unauthorized request to change payment routing."
        
        return {
            "is_scam": is_scam,
            "confidence": confidence,
            "reason": reason
        }

    async def analyze_cloud_repo(self, file_tree: str, content: str) -> dict:
        """
        Two-Phase Analysis:
        1. Recon: Determine Architecture, Stack.
        2. Audit: Find Deep Logic Flaws.
        
        NO MOCK DATA - Real Gemini API analysis only.
        """
        
        if not self.client:
            raise RuntimeError("Gemini client not initialized. Cannot perform analysis.")
        
        # --- PHASE 1: RECONNAISSANCE ---
        recon_prompt = f"""
        Analyze this file structure and return ONLY a valid JSON object (no markdown, no code blocks) with these exact keys:
        - app_type: string (e.g., "E-commerce Platform", "Social Network", "DevOps Tool")
        - tech_stack: array of strings (e.g., ["Next.js", "Python FastAPI", "PostgreSQL"])
        - architecture: string (e.g., "Microservices", "Monolith", "Serverless")
        - cloud_provider: string (e.g., "AWS", "GCP", "Azure", "Self-hosted")
        
        File Tree:
        {file_tree[:5000]}
        
        Return ONLY the JSON object, nothing else.
        """
        
        # --- PHASE 2: DEEP LOGIC AUDIT ---
        audit_prompt = f"""
        Review this codebase and identify ONE critical security vulnerability.
        Return ONLY a valid JSON object (no markdown, no code blocks) with these exact keys:
        - type: string (vulnerability name, e.g., "SQL Injection", "Race Condition", "IDOR")
        - severity: string ("CRITICAL" or "HIGH")
        - location: string (filename:line, e.g., "api/auth.py:42")
        - description: string (brief explanation of the vulnerability)
        - impact: string (business impact)
        - code_snippet: string (the vulnerable code)
        - fix_code: string (the secure version)
        
        If no critical vulnerabilities found, return:
        {{"type": "No Critical Vulnerabilities", "severity": "NONE", "location": "N/A", "description": "Code review found no critical security issues", "impact": "None", "code_snippet": "", "fix_code": ""}}
        
        Content (first 100KB):
        {content[:100000]}
        
        Return ONLY the JSON object, nothing else.
        """
        
        try:
            print("ðŸ§  Phase 1: Reconnaissance with Gemini AI...")
            # Phase 1: Reconnaissance using new SDK
            recon_resp = await self.client.aio.models.generate_content(
                model=self.model_name,
                contents=recon_prompt
            )
            recon_text = recon_resp.text.strip()
            
            # Clean up markdown code blocks if present
            recon_text = recon_text.replace("```json", "").replace("```", "").strip()
            
            # Try to parse JSON
            try:
                recon_data = json.loads(recon_text)
            except json.JSONDecodeError:
                # If JSON parsing fails, try to extract JSON from text
                import re
                json_match = re.search(r'\{.*\}', recon_text, re.DOTALL)
                if json_match:
                    recon_data = json.loads(json_match.group())
                else:
                    raise ValueError(f"Could not extract valid JSON from reconnaissance response")
            
            print(f"âœ… Reconnaissance: {recon_data.get('app_type', 'Unknown')}")
            
            print("ðŸ•µï¸ Phase 2: Deep Logic Audit with Gemini AI...")
            # Phase 2: Deep Logic Audit using new SDK
            audit_resp = await self.client.aio.models.generate_content(
                model=self.model_name,
                contents=audit_prompt
            )
            audit_text = audit_resp.text.strip()
            
            # Clean up markdown code blocks if present
            audit_text = audit_text.replace("```json", "").replace("```", "").strip()
            
            # Try to parse JSON
            try:
                audit_data = json.loads(audit_text)
            except json.JSONDecodeError:
                # If JSON parsing fails, try to extract JSON from text
                import re
                json_match = re.search(r'\{.*\}', audit_text, re.DOTALL)
                if json_match:
                    audit_data = json.loads(json_match.group())
                else:
                    raise ValueError(f"Could not extract valid JSON from audit response")
            
            print(f"âœ… Audit: {audit_data.get('type', 'Unknown')}")
            
            return {"recon": recon_data, "audit": audit_data}
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON Parse Error: {e}")
            print(f"Recon text: {recon_text[:200] if 'recon_text' in locals() else 'N/A'}")
            print(f"Audit text: {audit_text[:200] if 'audit_text' in locals() else 'N/A'}")
            raise ValueError(f"Gemini returned invalid JSON format: {e}")
        except Exception as e:
            print(f"âŒ Gemini AI Error: {e}")
            raise RuntimeError(f"Gemini AI analysis failed: {e}")



# Lazy Singleton Instance - created on first access, not at import time
_gemini_orchestrator_instance = None

def get_gemini_orchestrator():
    global _gemini_orchestrator_instance
    if _gemini_orchestrator_instance is None:
        print("DEBUG: Creating GeminiOrchestrator instance (lazy initialization)")
        _gemini_orchestrator_instance = GeminiOrchestrator()
    return _gemini_orchestrator_instance

# Backward compatibility - create a module-level proxy
class _OrchestratorProxy:
    """Proxy that lazily initializes the orchestrator on first attribute access"""
    def __getattr__(self, name):
        return getattr(get_gemini_orchestrator(), name)
    
    def __call__(self, *args, **kwargs):
        return get_gemini_orchestrator()(*args, **kwargs)

gemini_orchestrator = _OrchestratorProxy()

class AuditGenerator:
    def __init__(self, orchestrator: GeminiOrchestrator):
        self.orchestrator = orchestrator
        self.db = get_db_con()

    def generate_report(self) -> str:
        """
        Generates a Mock SOC2 Compliance Report.
        """
        return """
# SOC 2 Compliance Report (Generated by Vajra AI)
**Date**: 2024-12-26
**Auditor**: Vajra Security Engine (Simulated)

## Executive Summary
System analysis indicates a posture of **High Readiness**. Security controls are active and functioning within defined parameters.

## Incident Breakdown
- **Critical**: 0
- **High**: 0
- **Medium**: 2 (Simulated)
- **Low**: 5

## Compliance Status
- **Access Control**: PASSED (Fortress Mode Available)
- **Data Persistence**: PASSED (DuckDB Persistent Volume)
- **Monitoring**: PASSED (Real-time Threat Stream)

## Recommendations
1. Regularly rotate API keys.
2. Review vendor risk scores weekly.
"""
