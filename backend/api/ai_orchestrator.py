import google.generativeai as genai
import os
import json
from database import get_db_con

class GeminiOrchestrator:
    def __init__(self):
        # Lazy initialization - load API key when class is instantiated
        from dotenv import load_dotenv
        load_dotenv()
        
        self.api_key = os.getenv("GEMINI_API_KEY", "MOCK")
        print(f"DEBUG: API Key loaded: {self.api_key[:20]}..." if self.api_key != "MOCK" else "DEBUG: Using MOCK mode")
        
        # Initialize Gemini model if real API key is present
        if self.api_key != "MOCK":
            try:
                genai.configure(api_key=self.api_key)
                self.model = genai.GenerativeModel('gemini-1.5-pro')
                print(f"DEBUG: Gemini model initialized successfully: {self.model}")
            except Exception as e:
                print(f"DEBUG: Failed to initialize Gemini: {e}")
                self.model = None
        else:
            print("DEBUG: Skipping Gemini initialization - using mock mode")
            self.model = None

    def generate_remediation(self, findings: list) -> dict:
        """
        Mock: Returns a structured fix.
        """
        return {
            "description": "Mocked AI Remediation",
            "code_suggestion": "# Fixed code would follow...",
            "severity": "Medium"
        }

    def analyze_snippet(self, code: str, findings: list) -> dict:
        """
        Mock: Generates a fix for a specific code snippet.
        """
        return {
            "vulnerability": "Simulated Vulnerability",
            "explanation": "This is a simulated AI analysis response.",
            "fixed_code": "# Secure implementation\ndef secure_func():\n    pass",
            "severity": "Medium"
        }

    def generate_audit_report_text(self, context: str) -> str:
        """
        Mock: Generates a compliance report based on input context.
        Simulates "Thinking Mode" processing.
        """
        # Simple string matching to make the mock feel "Real" based on data passed
        has_critical_threats = "'severity': 'CRITICAL'" in context or "CRITICAL" in context
        has_risky_vendors = "risk_score" in context and ("100" in context or "95" in context)
        
        report = """
# SOC 2 TYPE II EVIDENCE REPORT
**Generated By**: Vajra AI Auditor (Gemini 3 Pro Exp)
**Date**: 2024-12-26
**Thinking Mode**: ENABLED (Analysis Depth: High)

## 1. Executive Summary
The organization's security posture is currently evaluated as **"""
        
        if has_critical_threats or has_risky_vendors:
             report += "AT RISK**.\nAutomated analysis has detected critical anomalies that require immediate remediation to satisfy Trust Services Criteria."
        else:
             report += "RESILIENT**.\nControls are operating effectively with no significant deviations detected."

        report += """

## 2. Control CC7.1: System Monitoring
**Criterion**: Entities must monitor limits and detect anomalies.
**Evidence Analysis**:
"""
        if has_critical_threats:
            report += "- ðŸ”´ **NON-COMPLIANT**: Critical severity threats detected in event stream. Immediate incident response logs required."
        else:
            report += "- ðŸŸ¢ **COMPLIANT**: No critical severity anomalies detected in the live threat stream. Continuous monitoring is active."

        report += """

## 3. Control CC8.1: Vulnerability Management
**Criterion**: Vulnerabilities are scanned and remediated.
**Evidence Analysis**:
- ðŸŸ¢ **COMPLIANT**: Recent scans (Trivy, Semgrep) indicate zero critical vulnerabilities in the codebase.
- **Trend**: consistent clean scans over the last 72 hours.

## 4. Control CC9.2: Vendor Risk Management
**Criterion**: Risks from third parties are assessed and managed.
**Evidence Analysis**:
"""
        if has_risky_vendors:
             report += "- âš ï¸ **OBSERVATION**: High-risk vendors detected in the supply chain (e.g., Legacy CRM, Stripe). Enhanced due diligence is recommended."
        else:
             report += "- ðŸŸ¢ **COMPLIANT**: All onboarded vendors fall within acceptable risk appetites."

        report += """

## 5. Auditor Opinion
**Determination**: """
        
        if has_critical_threats:
             report += "**QUALIFIED OPINION** (Exceptions Noted).\nThe presence of critical threats without documented resolution prevents an Unqualified opinion."
        else:
             report += "**UNQUALIFIED OPINION** (Clean).\nSystem controls appear effective and compliant with SOC 2 standards."

        return report

    def generate_gap_analysis(self, profile: dict, context: dict) -> dict:
        """
        Virtual CISO: Analyzes company profile and security logs to generate a roadmap.
        """
        # 1. Construct the Prompt
        # In a real scenario, this would go to Gemini.
        # For the hackathon/demo, we simulate the *response* of that prompt based on inputs.
        
        industry = profile.get("industry", "Unknown")
        region = profile.get("region", "Unknown")
        
        completed_actions = []
        if context.get("last_scan"): completed_actions.append("Code Vulnerability Scanning")
        if context.get("vendor_verification"): completed_actions.append("Vendor Identity Integrity")
        if context.get("ddos_protection"): completed_actions.append("Real-time Traffic Monitoring")
        
        # 2. Simulated AI Logic (The "Virtual CISO")
        gaps = []
        narrative = ""
        score = 65 # Base Score
        
        if "health" in industry.lower():
            narrative = f"As a {industry} provider in {region}, patient data privacy is your #1 risk. You are doing well with {', '.join(completed_actions) if completed_actions else 'basic security'}, but you are missing critical HIPAA safeguards."
            gaps.append({"regulation": "HIPAA", "gap": "Patient Data Encryption", "impact": "High", "fix_action": "Enable DB Encryption"})
            score = 70
        elif "fin" in industry.lower():
            narrative = f"For the {industry} sector, financial integrity is paramount. While you have {', '.join(completed_actions)}, PCI-DSS requires stricter network segmentation which is currently not detected."
            gaps.append({"regulation": "PCI-DSS", "gap": "Cardholder Data Isolation", "impact": "Critical", "fix_action": "Segment Network (VLAN)"})
            score = 60
        else:
             narrative = f"Operating in {region} requires strict data controls. Your current posture covers {', '.join(completed_actions)}, but you are exposed to general data breach liability."
             gaps.append({"regulation": "General Security", "gap": "MFA for Admin Access", "impact": "High", "fix_action": "Enforce MFA Policy"})

        if region.lower() in ["eu", "europe"]:
             gaps.append({"regulation": "GDPR", "gap": "Cookie Consent Log", "impact": "Medium", "fix_action": "Deploy Consent Banner"})
        
        return {
            "status": "Analysis Complete",
            "health_score": score,
            "narrative": narrative,
            "gaps": gaps
        }

        return {
            "status": "Analysis Complete",
            "health_score": score,
            "narrative": narrative,
            "gaps": gaps
        }

    def generate_phishing_email(self, industry: str, difficulty: str) -> dict:
        """
        AI Phish-Tank: Generates targeted phishing content.
        """
        # Mocking Gemini's creativity
        subject = "Urgent: Invoice Overdue"
        body = "Please review the attached invoice immediately."
        sender = "billing@internal-finance-dept.com"
        
        if "fin" in industry.lower():
            subject = "SWIFT Transfer Confirmation Pending"
            body = "A pending wire transfer of $45,000 requires your CEO approval. Login to the portal to authorize."
            sender = "swift-secure@citibank-support.com"
        elif "health" in industry.lower():
            subject = "HIPAA Compliance Audit - Action Required"
            body = "Your recent patient access logs show an anomaly. Please verify your credentials to avoid penalties."
            sender = "audit@hhs-gov-portal.com"
            
        return {
            "created_at": "Today",
            "sender": sender,
            "subject": subject,
            "body_preview": body,
            "difficulty": difficulty
        }

    def generate_security_moment(self, trigger: str, employee_id: str) -> dict:
        """
        Employee Coach: "Security Moment" interactive coaching.
        """
        if trigger == "suspect_link":
            return {
                "coach_name": "VAJRA Coach",
                "message": "Whoops! You clicked a simulated phishing link. Don't worry, you aren't in trouble.",
                "tip": "Always check the sender's domain. 'hhs-gov-portal.com' is not a real government site.",
                "rule": "The One Rule: If it asks for a login, check the URL twice."
            }
            
        return {"message": "Stay safe!"}

        return {"message": "Stay safe!"}

    def get_micro_learning_content(self, employee_name: str, risk_type: str) -> str:
        """
        Generates a 30-second 'Security Moment' for the employee.
        """
        # Mocking the AI response for the demo to ensure stability and speed
        
        if "Dark Web" in risk_type or "Leak" in risk_type:
             return f"""
             **Security Moment for {employee_name}**
             âš ï¸ **Risk Detected**: Your email was found in a recent public data breach. This is not your fault, but it is our problem to fix.
             ðŸ›¡ï¸ **Action**: Please change your VAJRA Dashboard password immediately.
             ðŸ’¡ **Pro-Tip**: Use a unique password manager so one leak doesn't compromise all your accounts.
             """
        
        return f"""
        **Security Moment for {employee_name}**
        âš ï¸ **Alert**: {risk_type} detected.
        ðŸ›¡ï¸ **Action**: Review your recent activity logs.
        ðŸ’¡ **Pro-Tip**: Enable 2FA on all sensitive accounts.
        """

        return f"""
        **Security Moment for {employee_name}**
        âš ï¸ **Alert**: {risk_type} detected.
        ðŸ›¡ï¸ **Action**: Review your recent activity logs.
        ðŸ’¡ **Pro-Tip**: Enable 2FA on all sensitive accounts.
        """

    def analyze_urgency(self, text: str, vendor: str) -> dict:
        """
        AI Context Filter: Determines if urgency is legitimate or scam.
        """
        # Mocking sophisticated context understanding
        text_lower = text.lower()
        is_scam = False
        confidence = 0.0
        reason = "Normal business communication."

        # Scam Patterns
        if "final notice" in text_lower or "immediate disconnection" in text_lower:
            # Context Check: Utilities often send these, but unknown vendors shouldn't
            if "cloud" in vendor.lower() or "service" in vendor.lower():
                 is_scam = True
                 confidence = 0.85
                 reason = "High-pressure tactics are untypical for Enterprise B2B SaaS."
            else:
                 # Likely utility bill
                 is_scam = False
                 confidence = 0.4
                 reason = "Urgency matches typical utility disconnection notice."
        
        if "change" in text_lower and "bank" in text_lower:
             is_scam = True
             confidence = 0.99
             reason = "CRITICAL: Unauthorized request to change payment routing."
        
        return {
            "is_scam": is_scam,
            "confidence": confidence,
            "reason": reason
        }

    async def analyze_cloud_repo(self, file_tree: str, content: str) -> dict:
        """
        Two-Phase Analysis:
        1. Recon: Determine Architecture, Stack.
        2. Audit: Find Deep Logic Flaws.
        """
        
        # --- PHASE 1: RECONNAISSANCE ---
        # "Scan this file tree and tell me what this app is, its stack, and cloud providers."
        recon_prompt = f"""
        Analyze this file structure and return a JSON object with:
        app_type, tech_stack (list), architecture (e.g. Microservices, Monolith), cloud_provider.
        File Tree:
        {file_tree}
        """
        
        # --- PHASE 2: DEEP LOGIC AUDIT ---
        # "Given this context and content, find CRITICAL Logic Flaws (Auth bypass, Race Conditions)."
        audit_prompt = f"""
        Review this Codebase Content. identify ONE Critical Logic Vulnerability (e.g. IDOR, Race Condition).
        Return JSON:
        type (Vulnerability Name),
        severity (Critical/High),
        location (Filename:Line),
        description (Short explanation),
        impact (Business impact),
        code_snippet (The vulnerable code),
        fix_code (The secure version)
        
        Content:
        {content[:100000]} 
        """
        
        # --- MOCK FALLBACK (Hackathon Speed) ---
        if self.model == "MockModel" or not self.model:
             # Simulate "Thinking" time in async if needed, but for now return instant
             return {
                 "recon": {
                     "app_type": "High-Frequency Trading Platform",
                     "tech_stack": ["Python (FastAPI)", "React", "PostgreSQL", "Redis"],
                     "architecture": "Event-Driven Microservices",
                     "cloud_provider": "AWS (Detected via config)"
                 },
                 "audit": {
                     "type": "Race Condition in Order Processing",
                     "severity": "CRITICAL",
                     "location": "backend/orders/processor.py:42",
                     "description": "Double-spend vulnerability. The system checks balance before deducting, but does not lock the row. Parallel requests can drain the wallet.",
                     "impact": "Potential loss of millions in unauthorized trades.",
                     "code_snippet": "if user.balance >= code_cost:\n    # Race Window Here\n    user.balance -= cost\n    execute_trade()",
                     "fix_code": "with db.transaction():\n    user = select_for_update(user_id)\n    if user.balance >= cost:\n        user.balance -= cost\n        execute_trade()"
                 }
             }
        
        # --- REAL GEMINI IMPLEMENTATION (If Key Present) ---
        try:
            # 1. Recon
            recon_resp = self.model.generate_content(recon_prompt)
            recon_data = json.loads(recon_resp.text.replace("```json", "").replace("```", ""))
            
            # 2. Audit
            audit_resp = self.model.generate_content(audit_prompt)
            audit_data = json.loads(audit_resp.text.replace("```json", "").replace("```", ""))
            
            return {"recon": recon_data, "audit": audit_data}
            
        except Exception as e:
            print(f"Gemini API Error: {e}. Falling back to Mock.")
            # Fallback to mock if API fails - set model to None to trigger mock path
            original_model = self.model
            self.model = None
            result = await self.analyze_cloud_repo(file_tree, content)
            self.model = original_model
            return result



# Lazy Singleton Instance - created on first access, not at import time
_gemini_orchestrator_instance = None

def get_gemini_orchestrator():
    global _gemini_orchestrator_instance
    if _gemini_orchestrator_instance is None:
        print("DEBUG: Creating GeminiOrchestrator instance (lazy initialization)")
        _gemini_orchestrator_instance = GeminiOrchestrator()
    return _gemini_orchestrator_instance

# Backward compatibility - create a module-level proxy
class _OrchestratorProxy:
    """Proxy that lazily initializes the orchestrator on first attribute access"""
    def __getattr__(self, name):
        return getattr(get_gemini_orchestrator(), name)
    
    def __call__(self, *args, **kwargs):
        return get_gemini_orchestrator()(*args, **kwargs)

gemini_orchestrator = _OrchestratorProxy()

class AuditGenerator:
    def __init__(self, orchestrator: GeminiOrchestrator):
        self.orchestrator = orchestrator
        self.db = get_db_con()

    def generate_report(self) -> str:
        """
        Generates a Mock SOC2 Compliance Report.
        """
        return """
# SOC 2 Compliance Report (Generated by Vajra AI)
**Date**: 2024-12-26
**Auditor**: Vajra Security Engine (Simulated)

## Executive Summary
System analysis indicates a posture of **High Readiness**. Security controls are active and functioning within defined parameters.

## Incident Breakdown
- **Critical**: 0
- **High**: 0
- **Medium**: 2 (Simulated)
- **Low**: 5

## Compliance Status
- **Access Control**: PASSED (Fortress Mode Available)
- **Data Persistence**: PASSED (DuckDB Persistent Volume)
- **Monitoring**: PASSED (Real-time Threat Stream)

## Recommendations
1. Regularly rotate API keys.
2. Review vendor risk scores weekly.
"""
